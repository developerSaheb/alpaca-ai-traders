{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stage 1: Installing dependencies and environment setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib3\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl (125kB)\n",
      "Installing collected packages: urllib3\n",
      "Successfully installed urllib3-1.25.7\n",
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/54/5f/e1b2d83b808f978f51b7ce109315154da3a3d4151aa59686002681f2e109/tensorflow-2.0.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/02/d0/1e8e60e61e748338e3a40e42f5dfeee63ccdecfc4f0894122b890bfb009a/pandas-0.25.3-cp37-cp37m-win_amd64.whl\n",
      "Collecting pandas-datareader\n",
      "  Using cached https://files.pythonhosted.org/packages/14/52/accb990baebe0063977f26e02df36aa7eb4015ed4e86f828cd76273cd6f1/pandas_datareader-0.8.1-py2.py3-none-any.whl\n",
      "Collecting tqdm\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/62/6f823501b3bf2bac242bd3c320b592ad1516b3081d82c77c1d813f076856/tqdm-4.39.0-py2.py3-none-any.whl (53kB)\n",
      "Collecting matplotlib\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/73/dc25ca27a9960539ef984921b0d42368445b856ae0861c3acba542b9a39c/matplotlib-3.1.2-cp37-cp37m-win_amd64.whl (9.1MB)\n",
      "Processing c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\\termcolor-1.1.0-cp37-none-any.whl\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/34/40/c6eae19892551ff91bdb15f884fef2d42d6f58da55ab18fa540851b48a32/numpy-1.17.4-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\marcin\\.conda\\envs\\aitrader\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\marcin\\.conda\\envs\\aitrader\\lib\\site-packages (from tensorflow) (1.13.0)\n",
      "Collecting tensorboard<2.1.0,>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
      "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Processing c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\d7\\de\\2e\\efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\\wrapt-1.11.2-cp37-cp37m-win_amd64.whl\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Processing c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\2c\\b1\\94\\43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\\opt_einsum-3.1.0-cp37-none-any.whl\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached https://files.pythonhosted.org/packages/b3/a8/91d878054bdacf586ed613bec64f5c26cc0a0a2af294377c7f29469a05f4/grpcio-1.25.0-cp37-cp37m-win_amd64.whl\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/3b/cc373fb204fbe90f1a31f5921e85c0e568481f488039ce210f69831b4204/protobuf-3.11.0-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Processing c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\a7\\15\\a0\\0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\\absl_py-0.8.1-cp37-none-any.whl\n",
      "Processing c:\\users\\marcin\\appdata\\local\\pip\\cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\\gast-0.2.2-cp37-none-any.whl\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\marcin\\.conda\\envs\\aitrader\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting requests>=2.3.0\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting lxml\n",
      "  Downloading https://files.pythonhosted.org/packages/aa/17/b9ccbdd50f66258d362561dbfe3cf4aaa60c82c4bba0302b3f52ab730b99/lxml-4.4.2-cp37-cp37m-win_amd64.whl (3.7MB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/0c/fc2e007d9a992d997f04a80125b0f183da7fb554f1de701bbb70a8e7d479/pyparsing-2.4.5-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/ea/e5474014a13ab2dcb5056608e0716c600c3d8a8bcffb10ed55ccd6a42eb0/kiwisolver-1.1.0-cp37-none-win_amd64.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\marcin\\.conda\\envs\\aitrader\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.1.post20191125)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Collecting h5py\n",
      "  Using cached https://files.pythonhosted.org/packages/a1/6b/7f62017e3f0b32438dd90bdc1ff0b7b1448b6cb04a1ed84f37b6de95cd7b/h5py-2.10.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\marcin\\.conda\\envs\\aitrader\\lib\\site-packages (from requests>=2.3.0->pandas-datareader) (1.25.7)\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marcin\\.conda\\envs\\aitrader\\lib\\site-packages (from requests>=2.3.0->pandas-datareader) (2019.11.28)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<3.2,>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Installing collected packages: termcolor, numpy, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, idna, chardet, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, grpcio, werkzeug, absl-py, markdown, tensorboard, tensorflow-estimator, astor, wrapt, keras-preprocessing, opt-einsum, h5py, keras-applications, gast, google-pasta, tensorflow, pytz, pandas, lxml, pandas-datareader, tqdm, pyparsing, cycler, kiwisolver, matplotlib\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 cachetools-3.1.1 chardet-3.0.4 cycler-0.10.0 gast-0.2.2 google-auth-1.7.1 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.8 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 lxml-4.4.2 markdown-3.1.1 matplotlib-3.1.2 numpy-1.17.4 oauthlib-3.1.0 opt-einsum-3.1.0 pandas-0.25.3 pandas-datareader-0.8.1 protobuf-3.11.0 pyasn1-0.4.8 pyasn1-modules-0.2.7 pyparsing-2.4.5 pytz-2019.3 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1 termcolor-1.1.0 tqdm-4.39.0 werkzeug-0.16.0 wrapt-1.11.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install urllib3\n",
    "# !pip install tensorflow pandas pandas-datareader tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **Stage 2: Improting project dependencies**\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as data_reader\n",
    "# try:\n",
    "#   # %tensorflow_version only exists in Colab.\n",
    "#   %tensorflow_version 2.x\n",
    "# except Exception:\n",
    "#   pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Stage 3: Building the AI Trader network**\n",
    "\n",
    "class AI_Trader():\n",
    "\n",
    "  def __init__(self, state_size, action_space=3, model_name=\"AITrader\", distributed=False): #Stay, Buy, Sell (actions)\n",
    "\n",
    "    self.state_size = state_size\n",
    "    self.action_space = action_space\n",
    "    self.distributed = distributed\n",
    "    self.memory = deque(maxlen=1000)\n",
    "    self.inventory = []\n",
    "    self.model_name = model_name\n",
    "\n",
    "    self.gamma = 0.95 # maximize the current \n",
    "    self.epsilon = 1.0 # start with random actions record\n",
    "    self.epsilon_final = 0.01 # if epsilon is less than this number stop randomizing it\n",
    "    self.epsilon_decay = 0.995\n",
    "\n",
    "    self.model = self.model_builder()\n",
    "\n",
    "  def model_builder(self):\n",
    "    if self.distributed:\n",
    "      distribute = tf.distribute.MirroredStrategy()\n",
    "\n",
    "      with distribute.scope():\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "\n",
    "    else:\n",
    "      model = tf.keras.models.Sequential()\n",
    "\n",
    "      model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "\n",
    "      model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "\n",
    "      model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "      model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))\n",
    "\n",
    "      model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "\n",
    "    return model\n",
    "\n",
    "  def trade(self, state):\n",
    "\n",
    "    if random.random() <= self.epsilon:\n",
    "      return random.randrange(self.action_space)\n",
    "\n",
    "    actions = self.model.predict(state)\n",
    "    return np.argmax(actions[0])\n",
    "\n",
    "  def batch_train(self, batch_size):\n",
    "\n",
    "    batch = []\n",
    "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "      batch.append(self.memory[i])\n",
    "\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "      reward = reward\n",
    "      if not done:\n",
    "        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "\n",
    "      target = self.model.predict(state)\n",
    "      target[0][action] = reward\n",
    "\n",
    "      self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "      if self.epsilon > self.epsilon_final:\n",
    "        self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Stage 4: Dataset preprocessing**\n",
    "\n",
    "# **Define helper functions**\n",
    "\n",
    "# **Sigmoid**\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# **Price format function**\n",
    "\n",
    "def stocks_price_format(n):\n",
    "  if n < 0:\n",
    "    return \"- $ {0:2f}\".format(abs(n))\n",
    "  else:\n",
    "    return \"$ {0:2f}\".format(abs(n))\n",
    "\n",
    "# **Dataset loader**\n",
    "\n",
    "# data_reader.DataReader(stock_name, data_source=\"yahoo\", start=2014, end=2016)\n",
    "\n",
    "def dataset_loader(stock_name):\n",
    "\n",
    "  #Complete the dataset loader function\n",
    "  # dataset = data_reader.DataReader(stock_name, data_source=\"yahoo\", start=2014, end=2015)\n",
    "  dataset = data_reader.DataReader(stock_name, data_source=\"yahoo\")\n",
    "\n",
    "  start_date = str(dataset.index[0]).split()[0]\n",
    "  end_date = str(dataset.index[-1]).split()[0]\n",
    "\n",
    "  close = dataset['Close']\n",
    "\n",
    "  return close\n",
    "\n",
    "# **State creator**\n",
    "\n",
    "def state_creator(data, timestep, window_size):\n",
    "\n",
    "  starting_id = timestep - window_size + 1\n",
    "\n",
    "  if starting_id >= 0:\n",
    "    windowed_data = data[starting_id:timestep+1]\n",
    "  else:\n",
    "    windowed_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n",
    "\n",
    "  state = []\n",
    "  for i in range(window_size - 1):\n",
    "    state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n",
    "\n",
    "  return np.array([state])\n",
    "\n",
    "# **Loading a dataset**\n",
    "\n",
    "stock_name = \"AAPL\"\n",
    "data = dataset_loader(stock_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                        | 0/1257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 11,171\n",
      "Trainable params: 11,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Episode: 0/1000\n",
      "AI Trader bought:  $ 116.470001\n",
      "AI Trader sold:  $ 118.629997  Profit: $ 2.159996\n",
      "AI Trader bought:  $ 115.489998\n",
      "AI Trader bought:  $ 115.000000\n",
      "AI Trader bought:  $ 112.400002\n",
      "AI Trader bought:  $ 114.120003\n",
      "AI Trader sold:  $ 111.949997  Profit: - $ 3.540001\n",
      "AI Trader sold:  $ 111.620003  Profit: - $ 3.379997\n",
      "AI Trader bought:  $ 109.730003\n",
      "AI Trader bought:  $ 108.230003\n",
      "AI Trader bought:  $ 111.779999\n",
      "AI Trader sold:  $ 112.940002  Profit: $ 0.540001\n",
      "AI Trader sold:  $ 112.540001  Profit: - $ 1.580002\n",
      "AI Trader sold:  $ 113.989998  Profit: $ 4.259995\n",
      "AI Trader sold:  $ 113.910004  Profit: $ 5.680000\n",
      "AI Trader bought:  $ 112.519997\n",
      "AI Trader sold:  $ 110.379997  Profit: - $ 1.400002\n",
      "AI Trader sold:  $ 107.750000  Profit: - $ 4.769997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▊                                                                                                                         | 38/1257 [00:24<1:04:04,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Trader bought:  $ 108.720001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▉                                                                                                                         | 40/1257 [00:31<1:09:14,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Trader sold:  $ 112.400002  Profit: $ 3.680000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▍                                                                                                                       | 55/1257 [01:19<1:02:41,  3.13s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-10ed79517039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m       \u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-d6cd5114feb6>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m       \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     return self._model_iteration(\n\u001b[0;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    607\u001b[0m   \u001b[1;31m# As a fallback for the data type that does not work with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m   \u001b[1;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[0;32m    320\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m     ))\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, count)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \"\"\"\n\u001b[1;32m--> 862\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mRepeatDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, count)\u001b[0m\n\u001b[0;32m   2885\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2886\u001b[0m         \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2887\u001b[1;33m         **self._flat_structure)\n\u001b[0m\u001b[0;32m   2888\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRepeatDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mrepeat_dataset\u001b[1;34m(input_dataset, count, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   5145\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5146\u001b[0m         \u001b[1;34m\"RepeatDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5147\u001b[1;33m         count, \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m   5148\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5149\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# **Stage 5: Training the AI Trader**\n",
    "\n",
    "# **Setting hyper parameters**\n",
    "\n",
    "window_size = 10\n",
    "episodes = 1000\n",
    "\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1\n",
    "\n",
    "# **Defining the Trader model**\n",
    "\n",
    "trader = AI_Trader(window_size, distributed=False)\n",
    "\n",
    "trader.model.summary()\n",
    "\n",
    "# **Training loop**\n",
    "\n",
    "for episode in range(episodes + 1):\n",
    "\n",
    "  print(\"Episode: {}/{}\".format(episode, episodes))\n",
    "\n",
    "  state = state_creator(data, 0, window_size + 1)\n",
    "\n",
    "  total_profit = 0\n",
    "  trader.inventory = []\n",
    "\n",
    "  for t in tqdm(range(data_samples)):\n",
    "\n",
    "    action = trader.trade(state)\n",
    "\n",
    "    next_state = state_creator(data, t+1, window_size + 1)\n",
    "    reward = 0\n",
    "\n",
    "    if action == 1: #Buying\n",
    "      trader.inventory.append(data[t])\n",
    "      print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
    "\n",
    "    elif action == 2 and len(trader.inventory) > 0: #Selling\n",
    "      buy_price = trader.inventory.pop(0)\n",
    "\n",
    "      reward = max(data[t] - buy_price, 0)\n",
    "      total_profit += data[t] - buy_price\n",
    "      print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price))\n",
    "\n",
    "    if t == data_samples - 1:\n",
    "      done = True\n",
    "    else:\n",
    "      done = False\n",
    "\n",
    "    trader.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "      print(\"#############################\")\n",
    "      print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
    "      print(\"#############################\")\n",
    "\n",
    "    if len(trader.memory) > batch_size:\n",
    "      trader.batch_train(batch_size)\n",
    "\n",
    "  if episode % 10 == 0:\n",
    "    trader.model.save(\"ai_trader_{}.h5\".format(episode))\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
